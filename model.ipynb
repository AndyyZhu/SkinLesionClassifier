{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndyyZhu/Skin_Lesion_Detection/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ7IfPWRB6Yv",
        "colab_type": "text"
      },
      "source": [
        "# **IMPORT GOOGLE DRIVE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBnVnvhhgH8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLG1snvWBvcy",
        "colab_type": "text"
      },
      "source": [
        "# **IMPORT LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUec1-juhKja",
        "colab_type": "code",
        "outputId": "7e57b889-210a-44df-fe6c-bb0b44983cf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKEqzqO_sfpk",
        "colab_type": "text"
      },
      "source": [
        "# **DATASET PREPROCESSING**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziAf2m--f_B5",
        "colab_type": "code",
        "outputId": "e4d38554-0697-495b-bf8b-c1ed0472b628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "# Import the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "# Create a new directory for the images\n",
        "base_dir = 'base_dir'\n",
        "os.mkdir(base_dir)\n",
        "\n",
        "# Training file directory\n",
        "train_dir = os.path.join(base_dir, 'train_dir')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "# Validation file directory\n",
        "val_dir = os.path.join(base_dir, 'val_dir')\n",
        "os.mkdir(val_dir)\n",
        "\n",
        "# Create new folders in the training directory for each of the classes\n",
        "nv = os.path.join(train_dir, 'nv')\n",
        "os.mkdir(nv)\n",
        "mel = os.path.join(train_dir, 'mel')\n",
        "os.mkdir(mel)\n",
        "bkl = os.path.join(train_dir, 'bkl')\n",
        "os.mkdir(bkl)\n",
        "bcc = os.path.join(train_dir, 'bcc')\n",
        "os.mkdir(bcc)\n",
        "akiec = os.path.join(train_dir, 'akiec')\n",
        "os.mkdir(akiec)\n",
        "vasc = os.path.join(train_dir, 'vasc')\n",
        "os.mkdir(vasc)\n",
        "df = os.path.join(train_dir, 'df')\n",
        "os.mkdir(df)\n",
        "\n",
        "# Create new folders in the validation directory for each of the classes\n",
        "nv = os.path.join(val_dir, 'nv')\n",
        "os.mkdir(nv)\n",
        "mel = os.path.join(val_dir, 'mel')\n",
        "os.mkdir(mel)\n",
        "bkl = os.path.join(val_dir, 'bkl')\n",
        "os.mkdir(bkl)\n",
        "bcc = os.path.join(val_dir, 'bcc')\n",
        "os.mkdir(bcc)\n",
        "akiec = os.path.join(val_dir, 'akiec')\n",
        "os.mkdir(akiec)\n",
        "vasc = os.path.join(val_dir, 'vasc')\n",
        "os.mkdir(vasc)\n",
        "df = os.path.join(val_dir, 'df')\n",
        "os.mkdir(df)\n",
        "\n",
        "# Read the metadata\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab_Notebooks/Skin_Lesion/HAM10000_metadata.csv')\n",
        "\n",
        "# Display some information in the dataset\n",
        "df.head()\n",
        "\n",
        "# Set y as the labels\n",
        "y = df['dx']\n",
        "\n",
        "# Split the metadata into training and validation\n",
        "df_train, df_val = train_test_split(df, test_size=0.1, random_state=101, stratify=y)\n",
        "\n",
        "# Print the shape of the training and validation split\n",
        "print(df_train.shape)\n",
        "print(df_val.shape)\n",
        "\n",
        "# Find the number of values in the training and validation set\n",
        "df_train['dx'].value_counts()\n",
        "df_val['dx'].value_counts()\n",
        "\n",
        "# Transfer the images into folders\n",
        "# Set the image id as the index\n",
        "df.set_index('image_id', inplace=True)\n",
        "\n",
        "# Get a list of images in each of the two folders\n",
        "folder_1 = os.listdir('/content/drive/My Drive/Colab_Notebooks/Skin_Lesion/HAM10000_images_part_1')\n",
        "folder_2 = os.listdir('/content/drive/My Drive/Colab_Notebooks/Skin_Lesion/HAM10000_images_part_2')\n",
        "\n",
        "# Get a list of train and val images\n",
        "train_list = list(df_train['image_id'])\n",
        "val_list = list(df_val['image_id'])\n",
        "\n",
        "# Transfer the training images\n",
        "for image in train_list:\n",
        "\n",
        "    fname = image + '.jpg'\n",
        "    label = df.loc[image, 'dx']\n",
        "\n",
        "    if fname in folder_1:\n",
        "        # source path to image\n",
        "        src = os.path.join('/content/drive/My Drive/Colab_Notebooks/Skin_Lesion/HAM10000_images_part_1', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(train_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    if fname in folder_2:\n",
        "        # source path to image\n",
        "        src = os.path.join('/content/drive/My Drive/Colab_Notebooks/Skin_Lesion/HAM10000_images_part_2', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(train_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "# Transfer the validation images\n",
        "for image in val_list:\n",
        "\n",
        "    fname = image + '.jpg'\n",
        "    label = df.loc[image, 'dx']\n",
        "\n",
        "    if fname in folder_1:\n",
        "        # source path to image\n",
        "        src = os.path.join('/content/drive/My Drive/Colab_Notebooks/Skin_Lesion/HAM10000_images_part_1', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(val_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    if fname in folder_2:\n",
        "        # source path to image\n",
        "        src = os.path.join('/content/drive/My Drive/Colab_Notebooks/Skin_Lesion/HAM10000_images_part_2', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(val_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "# Check how many training images are in each folder\n",
        "print(len(os.listdir('base_dir/train_dir/nv')))\n",
        "print(len(os.listdir('base_dir/train_dir/mel')))\n",
        "print(len(os.listdir('base_dir/train_dir/bkl')))\n",
        "print(len(os.listdir('base_dir/train_dir/bcc')))\n",
        "print(len(os.listdir('base_dir/train_dir/akiec')))\n",
        "print(len(os.listdir('base_dir/train_dir/vasc')))\n",
        "print(len(os.listdir('base_dir/train_dir/df')))\n",
        "\n",
        "# Check how many validation images are in each folder\n",
        "print(len(os.listdir('base_dir/val_dir/nv')))\n",
        "print(len(os.listdir('base_dir/val_dir/mel')))\n",
        "print(len(os.listdir('base_dir/val_dir/bkl')))\n",
        "print(len(os.listdir('base_dir/val_dir/bcc')))\n",
        "print(len(os.listdir('base_dir/val_dir/akiec')))\n",
        "print(len(os.listdir('base_dir/val_dir/vasc')))\n",
        "print(len(os.listdir('base_dir/val_dir/df')))\n",
        "\n",
        "# Augment the data\n",
        "# Class 'nv' is not going to be augmented\n",
        "class_list = ['mel', 'bkl', 'bcc', 'akiec', 'vasc', 'df']\n",
        "\n",
        "for item in class_list:\n",
        "\n",
        "    # Create a temporary directory for the augmented images\n",
        "    aug_dir = 'aug_dir'\n",
        "    os.mkdir(aug_dir)\n",
        "\n",
        "    # Create a directory within the base dir to store images of the same class\n",
        "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
        "    os.mkdir(img_dir)\n",
        "\n",
        "    # Choose a class\n",
        "    img_class = item\n",
        "\n",
        "    # List all the images in the directory\n",
        "    img_list = os.listdir('base_dir/train_dir/' + img_class)\n",
        "\n",
        "    # Copy images from the class train dir to the img_dir\n",
        "    for fname in img_list:\n",
        "        # source path to image\n",
        "        src = os.path.join('base_dir/train_dir/' + img_class, fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(img_dir, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    # point to a dir containing the images and not to the images themselves\n",
        "    path = aug_dir\n",
        "    save_path = 'base_dir/train_dir/' + img_class\n",
        "\n",
        "    # Create a data generator to augment the images in real time\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=180,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        # brightness_range=(0.9,1.1),\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    batch_size = 50\n",
        "\n",
        "    aug_datagen = datagen.flow_from_directory(path,\n",
        "                                              save_to_dir=save_path,\n",
        "                                              save_format='jpg',\n",
        "                                              target_size=(224, 224),\n",
        "                                              batch_size=batch_size)\n",
        "\n",
        "    # Generate the augmented images and add them to the training folders\n",
        "    num_aug_images_wanted = 6000  # total number of images we want to have in each class\n",
        "    num_files = len(os.listdir(img_dir))\n",
        "    num_batches = int(np.ceil((num_aug_images_wanted - num_files) / batch_size))\n",
        "\n",
        "    # run the generator and create about 6000 augmented images\n",
        "    for i in range(0, num_batches):\n",
        "        imgs, labels = next(aug_datagen)\n",
        "\n",
        "    # delete temporary directory with the raw image files\n",
        "    shutil.rmtree('aug_dir')\n",
        "\n",
        "# Check how many train images are each folder (original + augmented)\n",
        "print(len(os.listdir('base_dir/train_dir/nv')))\n",
        "print(len(os.listdir('base_dir/train_dir/mel')))\n",
        "print(len(os.listdir('base_dir/train_dir/bkl')))\n",
        "print(len(os.listdir('base_dir/train_dir/bcc')))\n",
        "print(len(os.listdir('base_dir/train_dir/akiec')))\n",
        "print(len(os.listdir('base_dir/train_dir/vasc')))\n",
        "print(len(os.listdir('base_dir/train_dir/df')))\n",
        "\n",
        "# Check how many validation images are in each folder\n",
        "print(len(os.listdir('base_dir/val_dir/nv')))\n",
        "print(len(os.listdir('base_dir/val_dir/mel')))\n",
        "print(len(os.listdir('base_dir/val_dir/bkl')))\n",
        "print(len(os.listdir('base_dir/val_dir/bcc')))\n",
        "print(len(os.listdir('base_dir/val_dir/akiec')))\n",
        "print(len(os.listdir('base_dir/val_dir/vasc')))\n",
        "print(len(os.listdir('base_dir/val_dir/df')))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9013, 7)\n",
            "(1002, 7)\n",
            "6034\n",
            "1002\n",
            "989\n",
            "463\n",
            "294\n",
            "128\n",
            "103\n",
            "671\n",
            "111\n",
            "110\n",
            "51\n",
            "33\n",
            "14\n",
            "12\n",
            "Found 1002 images belonging to 1 classes.\n",
            "Found 989 images belonging to 1 classes.\n",
            "Found 463 images belonging to 1 classes.\n",
            "Found 294 images belonging to 1 classes.\n",
            "Found 128 images belonging to 1 classes.\n",
            "Found 103 images belonging to 1 classes.\n",
            "6034\n",
            "5810\n",
            "5984\n",
            "5606\n",
            "5930\n",
            "5170\n",
            "4170\n",
            "671\n",
            "111\n",
            "110\n",
            "51\n",
            "33\n",
            "14\n",
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lifbfz-ACna8",
        "colab_type": "text"
      },
      "source": [
        "# **MORE IMPORT + VARIABLES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1BY3sL-CErm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4_HXVLrDBwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The paths for the training and validation images\n",
        "train_path = 'base_dir/train_dir'\n",
        "valid_path = 'base_dir/val_dir'\n",
        "\n",
        "# Declare a few useful values\n",
        "num_train_samples = 9013\n",
        "num_val_samples = 1002\n",
        "train_batch_size = 10\n",
        "val_batch_size = 10\n",
        "image_size = 224\n",
        "\n",
        "# Declare how many steps are needed in an iteration\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmSbMNUPC9Uf",
        "colab_type": "text"
      },
      "source": [
        "# **ML MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQTHT8UkDQd6",
        "colab_type": "code",
        "outputId": "16e8bfae-fadf-4dad-b166-def979febb36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Set up generators\n",
        "train_batches = ImageDataGenerator(\n",
        "    preprocessing_function= \\\n",
        "        keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=train_batch_size)\n",
        "\n",
        "valid_batches = ImageDataGenerator(\n",
        "    preprocessing_function= \\\n",
        "        keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=val_batch_size)\n",
        "\n",
        "test_batches = ImageDataGenerator(\n",
        "    preprocessing_function= \\\n",
        "        keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=val_batch_size,\n",
        "    shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 38704 images belonging to 7 classes.\n",
            "Found 1002 images belonging to 7 classes.\n",
            "Found 1002 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cys56rmEDQtl",
        "colab_type": "code",
        "outputId": "f584c4ea-b05c-45f1-dee7-6b6bcb13b95b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "# create a copy of a mobilenet model\n",
        "mobile = keras.applications.mobilenet.MobileNet()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf.h5\n",
            "17227776/17225924 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGVQG6X3FRHk",
        "colab_type": "code",
        "outputId": "77f7d011-6d9a-45f2-96d0-da823060a496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# See a summary of the layers in the model\n",
        "mobile.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"mobilenet_1.00_224\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_preds (Conv2D)          (None, 1, 1, 1000)        1025000   \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "act_softmax (Activation)     (None, 1000)              0         \n",
            "=================================================================\n",
            "Total params: 4,253,864\n",
            "Trainable params: 4,231,976\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YbF82K-FkFG",
        "colab_type": "code",
        "outputId": "791a493e-9765-42ae-f87b-4a05fdc4b682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Modify the model\n",
        "# Exclude the last 5 layers of the model\n",
        "x = mobile.layers[-6].output\n",
        "# Add a dropout and dense layer for predictions\n",
        "x = Dropout(0.25)(x)\n",
        "predictions = Dense(7, activation='softmax')(x)\n",
        "\n",
        "# Create a new model with the new outputs\n",
        "model = Model(inputs=mobile.input, outputs=predictions)\n",
        "\n",
        "# See a summary of the new layers in the model\n",
        "model.summary()\n",
        "\n",
        "# Freeze the weights of the layers that we aren't training (training the last 23)\n",
        "for layer in model.layers[:-23]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Train the model\n",
        "# Define Top2 and Top3 Accuracy\n",
        "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
        "\n",
        "def top_3_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
        "\n",
        "def top_2_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])\n",
        "\n",
        "# Add weights to make the model more sensitive to melanoma\n",
        "class_weights={\n",
        "    0: 1.0,  # akiec\n",
        "    1: 1.0,  # bcc\n",
        "    2: 1.0,  # bkl\n",
        "    3: 1.0,  # df\n",
        "    4: 3.0,  # mel\n",
        "    5: 1.0,  # nv\n",
        "    6: 1.0,  # vasc\n",
        "}\n",
        "\n",
        "# Declare the filepath for the saved model\n",
        "filepath = \"model.h5\"\n",
        "\n",
        "# Declare a checkpoint to save the best version of the model\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_top_3_accuracy', verbose=1,\n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "# Reduce the learning rate as the learning stagnates\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=2,\n",
        "                              verbose=1, mode='max', min_lr=0.00001)\n",
        "\n",
        "callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit_generator(train_batches,\n",
        "                              steps_per_epoch=train_steps,\n",
        "                              class_weight=class_weights,\n",
        "                              validation_data=valid_batches,\n",
        "                              validation_steps=val_steps,\n",
        "                              epochs=30,\n",
        "                              verbose=1,\n",
        "                              callbacks=callbacks_list)\n",
        "\n",
        "# Evaluate the model\n",
        "# Evaluation of the last epoch\n",
        "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\n",
        "model.evaluate_generator(test_batches, steps=val_steps)\n",
        "\n",
        "print('val_loss:', val_loss)\n",
        "print('val_cat_acc:', val_cat_acc)\n",
        "print('val_top_2_acc:', val_top_2_acc)\n",
        "print('val_top_3_acc:', val_top_3_acc)\n",
        "\n",
        "# Evaluation of the best epoch\n",
        "model.load_weights('model.h5')\n",
        "\n",
        "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\n",
        "model.evaluate_generator(test_batches, steps=val_steps)\n",
        "\n",
        "print('val_loss:', val_loss)\n",
        "print('val_cat_acc:', val_cat_acc)\n",
        "print('val_top_2_acc:', val_top_2_acc)\n",
        "print('val_top_3_acc:', val_top_3_acc)\n",
        "\n",
        "# Create a confusion matrix of the test images\n",
        "test_labels = test_batches.classes\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict_generator(test_batches, steps=val_steps, verbose=1)\n",
        "\n",
        "# Declare a function for plotting the confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))\n",
        "\n",
        "cm_plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'mel','nv', 'vasc']\n",
        "\n",
        "plot_confusion_matrix(cm, cm_plot_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
            "_________________________________________________________________\n",
            "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
            "_________________________________________________________________\n",
            "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
            "_________________________________________________________________\n",
            "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
            "_________________________________________________________________\n",
            "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
            "_________________________________________________________________\n",
            "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
            "_________________________________________________________________\n",
            "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
            "_________________________________________________________________\n",
            "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
            "_________________________________________________________________\n",
            "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
            "_________________________________________________________________\n",
            "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
            "_________________________________________________________________\n",
            "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
            "_________________________________________________________________\n",
            "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
            "_________________________________________________________________\n",
            "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
            "_________________________________________________________________\n",
            "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 7175      \n",
            "=================================================================\n",
            "Total params: 3,236,039\n",
            "Trainable params: 3,214,151\n",
            "Non-trainable params: 21,888\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/30\n",
            "902/902 [==============================] - 62s 69ms/step - loss: 1.7522 - categorical_accuracy: 0.5218 - top_2_accuracy: 0.7227 - top_3_accuracy: 0.8402 - val_loss: 1.0804 - val_categorical_accuracy: 0.6806 - val_top_2_accuracy: 0.8004 - val_top_3_accuracy: 0.8723\n",
            "\n",
            "Epoch 00001: val_top_3_accuracy improved from -inf to 0.87226, saving model to model.h5\n",
            "Epoch 2/30\n",
            "902/902 [==============================] - 55s 61ms/step - loss: 1.2228 - categorical_accuracy: 0.6254 - top_2_accuracy: 0.8098 - top_3_accuracy: 0.9171 - val_loss: 1.1620 - val_categorical_accuracy: 0.6297 - val_top_2_accuracy: 0.8024 - val_top_3_accuracy: 0.8902\n",
            "\n",
            "Epoch 00002: val_top_3_accuracy improved from 0.87226 to 0.89022, saving model to model.h5\n",
            "Epoch 3/30\n",
            "902/902 [==============================] - 56s 62ms/step - loss: 1.1697 - categorical_accuracy: 0.6324 - top_2_accuracy: 0.8280 - top_3_accuracy: 0.9262 - val_loss: 1.1193 - val_categorical_accuracy: 0.6607 - val_top_2_accuracy: 0.8144 - val_top_3_accuracy: 0.8842\n",
            "\n",
            "Epoch 00003: val_top_3_accuracy did not improve from 0.89022\n",
            "Epoch 4/30\n",
            "902/902 [==============================] - 55s 61ms/step - loss: 1.0827 - categorical_accuracy: 0.6690 - top_2_accuracy: 0.8522 - top_3_accuracy: 0.9402 - val_loss: 4.3228 - val_categorical_accuracy: 0.3114 - val_top_2_accuracy: 0.7116 - val_top_3_accuracy: 0.8353\n",
            "\n",
            "Epoch 00004: val_top_3_accuracy did not improve from 0.89022\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "Epoch 5/30\n",
            "902/902 [==============================] - 54s 60ms/step - loss: 0.8918 - categorical_accuracy: 0.7190 - top_2_accuracy: 0.8896 - top_3_accuracy: 0.9652 - val_loss: 1.0310 - val_categorical_accuracy: 0.6377 - val_top_2_accuracy: 0.8174 - val_top_3_accuracy: 0.9102\n",
            "\n",
            "Epoch 00005: val_top_3_accuracy improved from 0.89022 to 0.91018, saving model to model.h5\n",
            "Epoch 6/30\n",
            "902/902 [==============================] - 51s 57ms/step - loss: 0.8265 - categorical_accuracy: 0.7463 - top_2_accuracy: 0.9071 - top_3_accuracy: 0.9712 - val_loss: 1.3615 - val_categorical_accuracy: 0.5469 - val_top_2_accuracy: 0.8014 - val_top_3_accuracy: 0.9042\n",
            "\n",
            "Epoch 00006: val_top_3_accuracy did not improve from 0.91018\n",
            "Epoch 7/30\n",
            "902/902 [==============================] - 52s 57ms/step - loss: 0.8151 - categorical_accuracy: 0.7480 - top_2_accuracy: 0.9100 - top_3_accuracy: 0.9703 - val_loss: 1.2572 - val_categorical_accuracy: 0.6936 - val_top_2_accuracy: 0.8323 - val_top_3_accuracy: 0.8982\n",
            "\n",
            "Epoch 00007: val_top_3_accuracy did not improve from 0.91018\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "Epoch 8/30\n",
            "902/902 [==============================] - 51s 57ms/step - loss: 0.6924 - categorical_accuracy: 0.7816 - top_2_accuracy: 0.9331 - top_3_accuracy: 0.9792 - val_loss: 1.1725 - val_categorical_accuracy: 0.5888 - val_top_2_accuracy: 0.8383 - val_top_3_accuracy: 0.9242\n",
            "\n",
            "Epoch 00008: val_top_3_accuracy improved from 0.91018 to 0.92415, saving model to model.h5\n",
            "Epoch 9/30\n",
            "902/902 [==============================] - 50s 55ms/step - loss: 0.6506 - categorical_accuracy: 0.7960 - top_2_accuracy: 0.9353 - top_3_accuracy: 0.9826 - val_loss: 1.3671 - val_categorical_accuracy: 0.5369 - val_top_2_accuracy: 0.8104 - val_top_3_accuracy: 0.9222\n",
            "\n",
            "Epoch 00009: val_top_3_accuracy did not improve from 0.92415\n",
            "Epoch 10/30\n",
            "902/902 [==============================] - 50s 55ms/step - loss: 0.5814 - categorical_accuracy: 0.8174 - top_2_accuracy: 0.9461 - top_3_accuracy: 0.9880 - val_loss: 1.3253 - val_categorical_accuracy: 0.6118 - val_top_2_accuracy: 0.8014 - val_top_3_accuracy: 0.8832\n",
            "\n",
            "Epoch 00010: val_top_3_accuracy did not improve from 0.92415\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "Epoch 11/30\n",
            "902/902 [==============================] - 50s 56ms/step - loss: 0.5330 - categorical_accuracy: 0.8354 - top_2_accuracy: 0.9504 - top_3_accuracy: 0.9885 - val_loss: 1.2547 - val_categorical_accuracy: 0.5888 - val_top_2_accuracy: 0.8114 - val_top_3_accuracy: 0.9242\n",
            "\n",
            "Epoch 00011: val_top_3_accuracy improved from 0.92415 to 0.92415, saving model to model.h5\n",
            "Epoch 12/30\n",
            "902/902 [==============================] - 51s 56ms/step - loss: 0.5181 - categorical_accuracy: 0.8358 - top_2_accuracy: 0.9544 - top_3_accuracy: 0.9906 - val_loss: 1.0620 - val_categorical_accuracy: 0.6547 - val_top_2_accuracy: 0.8523 - val_top_3_accuracy: 0.9192\n",
            "\n",
            "Epoch 00012: val_top_3_accuracy did not improve from 0.92415\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "Epoch 13/30\n",
            "902/902 [==============================] - 52s 58ms/step - loss: 0.4820 - categorical_accuracy: 0.8524 - top_2_accuracy: 0.9610 - top_3_accuracy: 0.9916 - val_loss: 1.0333 - val_categorical_accuracy: 0.7226 - val_top_2_accuracy: 0.8673 - val_top_3_accuracy: 0.9291\n",
            "\n",
            "Epoch 00013: val_top_3_accuracy improved from 0.92415 to 0.92914, saving model to model.h5\n",
            "Epoch 14/30\n",
            "902/902 [==============================] - 51s 56ms/step - loss: 0.4134 - categorical_accuracy: 0.8726 - top_2_accuracy: 0.9692 - top_3_accuracy: 0.9943 - val_loss: 1.1297 - val_categorical_accuracy: 0.6437 - val_top_2_accuracy: 0.8683 - val_top_3_accuracy: 0.9301\n",
            "\n",
            "Epoch 00014: val_top_3_accuracy improved from 0.92914 to 0.93014, saving model to model.h5\n",
            "Epoch 15/30\n",
            "902/902 [==============================] - 50s 56ms/step - loss: 0.3945 - categorical_accuracy: 0.8758 - top_2_accuracy: 0.9728 - top_3_accuracy: 0.9938 - val_loss: 1.2519 - val_categorical_accuracy: 0.6287 - val_top_2_accuracy: 0.8393 - val_top_3_accuracy: 0.9162\n",
            "\n",
            "Epoch 00015: val_top_3_accuracy did not improve from 0.93014\n",
            "Epoch 16/30\n",
            "902/902 [==============================] - 50s 55ms/step - loss: 0.4090 - categorical_accuracy: 0.8739 - top_2_accuracy: 0.9707 - top_3_accuracy: 0.9937 - val_loss: 1.3071 - val_categorical_accuracy: 0.6078 - val_top_2_accuracy: 0.8313 - val_top_3_accuracy: 0.9341\n",
            "\n",
            "Epoch 00016: val_top_3_accuracy improved from 0.93014 to 0.93413, saving model to model.h5\n",
            "Epoch 17/30\n",
            "902/902 [==============================] - 49s 54ms/step - loss: 0.4032 - categorical_accuracy: 0.8754 - top_2_accuracy: 0.9702 - top_3_accuracy: 0.9948 - val_loss: 1.2493 - val_categorical_accuracy: 0.6128 - val_top_2_accuracy: 0.8373 - val_top_3_accuracy: 0.9341\n",
            "\n",
            "Epoch 00017: val_top_3_accuracy did not improve from 0.93413\n",
            "Epoch 18/30\n",
            "902/902 [==============================] - 49s 54ms/step - loss: 0.3644 - categorical_accuracy: 0.8876 - top_2_accuracy: 0.9753 - top_3_accuracy: 0.9960 - val_loss: 1.2438 - val_categorical_accuracy: 0.6228 - val_top_2_accuracy: 0.8483 - val_top_3_accuracy: 0.9351\n",
            "\n",
            "Epoch 00018: val_top_3_accuracy improved from 0.93413 to 0.93513, saving model to model.h5\n",
            "Epoch 19/30\n",
            "902/902 [==============================] - 49s 54ms/step - loss: 0.3499 - categorical_accuracy: 0.8916 - top_2_accuracy: 0.9779 - top_3_accuracy: 0.9959 - val_loss: 1.4007 - val_categorical_accuracy: 0.5988 - val_top_2_accuracy: 0.8224 - val_top_3_accuracy: 0.9142\n",
            "\n",
            "Epoch 00019: val_top_3_accuracy did not improve from 0.93513\n",
            "Epoch 20/30\n",
            "902/902 [==============================] - 49s 54ms/step - loss: 0.3505 - categorical_accuracy: 0.8899 - top_2_accuracy: 0.9778 - top_3_accuracy: 0.9962 - val_loss: 1.3571 - val_categorical_accuracy: 0.5988 - val_top_2_accuracy: 0.8234 - val_top_3_accuracy: 0.9182\n",
            "\n",
            "Epoch 00020: val_top_3_accuracy did not improve from 0.93513\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "Epoch 21/30\n",
            "902/902 [==============================] - 49s 54ms/step - loss: 0.3423 - categorical_accuracy: 0.8928 - top_2_accuracy: 0.9780 - top_3_accuracy: 0.9962 - val_loss: 1.2801 - val_categorical_accuracy: 0.6228 - val_top_2_accuracy: 0.8403 - val_top_3_accuracy: 0.9251\n",
            "\n",
            "Epoch 00021: val_top_3_accuracy did not improve from 0.93513\n",
            "Epoch 22/30\n",
            "902/902 [==============================] - 48s 53ms/step - loss: 0.3064 - categorical_accuracy: 0.9073 - top_2_accuracy: 0.9785 - top_3_accuracy: 0.9958 - val_loss: 1.5781 - val_categorical_accuracy: 0.5639 - val_top_2_accuracy: 0.8194 - val_top_3_accuracy: 0.9172\n",
            "\n",
            "Epoch 00022: val_top_3_accuracy did not improve from 0.93513\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "Epoch 23/30\n",
            "902/902 [==============================] - 48s 54ms/step - loss: 0.2928 - categorical_accuracy: 0.9103 - top_2_accuracy: 0.9812 - top_3_accuracy: 0.9975 - val_loss: 1.5928 - val_categorical_accuracy: 0.5679 - val_top_2_accuracy: 0.8084 - val_top_3_accuracy: 0.9072\n",
            "\n",
            "Epoch 00023: val_top_3_accuracy did not improve from 0.93513\n",
            "Epoch 24/30\n",
            "902/902 [==============================] - 48s 54ms/step - loss: 0.2892 - categorical_accuracy: 0.9083 - top_2_accuracy: 0.9812 - top_3_accuracy: 0.9979 - val_loss: 1.5694 - val_categorical_accuracy: 0.5609 - val_top_2_accuracy: 0.8114 - val_top_3_accuracy: 0.9022\n",
            "\n",
            "Epoch 00024: val_top_3_accuracy did not improve from 0.93513\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
            "Epoch 25/30\n",
            "902/902 [==============================] - 49s 54ms/step - loss: 0.2922 - categorical_accuracy: 0.9094 - top_2_accuracy: 0.9833 - top_3_accuracy: 0.9969 - val_loss: 1.5843 - val_categorical_accuracy: 0.5589 - val_top_2_accuracy: 0.8124 - val_top_3_accuracy: 0.9042\n",
            "\n",
            "Epoch 00025: val_top_3_accuracy did not improve from 0.93513\n",
            "Epoch 26/30\n",
            "902/902 [==============================] - 49s 55ms/step - loss: 0.3014 - categorical_accuracy: 0.9090 - top_2_accuracy: 0.9823 - top_3_accuracy: 0.9973 - val_loss: 1.5224 - val_categorical_accuracy: 0.5689 - val_top_2_accuracy: 0.8204 - val_top_3_accuracy: 0.9122\n",
            "\n",
            "Epoch 00026: val_top_3_accuracy did not improve from 0.93513\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.9062499126885086e-05.\n",
            "Epoch 27/30\n",
            "902/902 [==============================] - 49s 55ms/step - loss: 0.2814 - categorical_accuracy: 0.9114 - top_2_accuracy: 0.9834 - top_3_accuracy: 0.9976 - val_loss: 1.4401 - val_categorical_accuracy: 0.5948 - val_top_2_accuracy: 0.8343 - val_top_3_accuracy: 0.9172\n",
            "\n",
            "Epoch 00027: val_top_3_accuracy did not improve from 0.93513\n",
            "Epoch 28/30\n",
            "902/902 [==============================] - 49s 54ms/step - loss: 0.2788 - categorical_accuracy: 0.9150 - top_2_accuracy: 0.9857 - top_3_accuracy: 0.9980 - val_loss: 1.4872 - val_categorical_accuracy: 0.5808 - val_top_2_accuracy: 0.8263 - val_top_3_accuracy: 0.9152\n",
            "\n",
            "Epoch 00028: val_top_3_accuracy did not improve from 0.93513\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.9531249563442543e-05.\n",
            "Epoch 29/30\n",
            "902/902 [==============================] - 49s 54ms/step - loss: 0.2786 - categorical_accuracy: 0.9177 - top_2_accuracy: 0.9818 - top_3_accuracy: 0.9976 - val_loss: 1.5337 - val_categorical_accuracy: 0.5719 - val_top_2_accuracy: 0.8184 - val_top_3_accuracy: 0.9112\n",
            "\n",
            "Epoch 00029: val_top_3_accuracy did not improve from 0.93513\n",
            "Epoch 30/30\n",
            "902/902 [==============================] - 48s 53ms/step - loss: 0.2802 - categorical_accuracy: 0.9120 - top_2_accuracy: 0.9830 - top_3_accuracy: 0.9971 - val_loss: 1.5384 - val_categorical_accuracy: 0.5729 - val_top_2_accuracy: 0.8244 - val_top_3_accuracy: 0.9102\n",
            "\n",
            "Epoch 00030: val_top_3_accuracy did not improve from 0.93513\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "val_loss: 1.5383665294373898\n",
            "val_cat_acc: 0.5728542979159755\n",
            "val_top_2_acc: 0.8243512941186062\n",
            "val_top_3_acc: 0.9101796338777104\n",
            "val_loss: 1.243808319150589\n",
            "val_cat_acc: 0.6227544935014909\n",
            "val_top_2_acc: 0.8483033882019049\n",
            "val_top_3_acc: 0.935129736354965\n",
            "101/101 [==============================] - 10s 98ms/step\n",
            "Confusion matrix, without normalization\n",
            "[[ 23   6   0   3   1   0   0]\n",
            " [  9  35   0   3   2   2   0]\n",
            " [ 19   6  28   4  36  17   0]\n",
            " [  2   0   0  10   0   0   0]\n",
            " [ 11   3   0   8  63  25   1]\n",
            " [ 11  32  13  56  99 457   3]\n",
            " [  0   1   2   2   0   1   8]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAEYCAYAAAApuP8NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEbjYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}