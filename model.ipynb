{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndyyZhu/Skin_Lesion_Detection/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ7IfPWRB6Yv",
        "colab_type": "text"
      },
      "source": [
        "# **IMPORT GOOGLE DRIVE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBnVnvhhgH8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLG1snvWBvcy",
        "colab_type": "text"
      },
      "source": [
        "# **IMPORT LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUec1-juhKja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKEqzqO_sfpk",
        "colab_type": "text"
      },
      "source": [
        "# **DATASET PREPROCESSING**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziAf2m--f_B5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shutil\n",
        "\n",
        "# Create a new directory for the images\n",
        "base_dir = 'base_dir'\n",
        "os.mkdir(base_dir)\n",
        "\n",
        "# Training file directory\n",
        "train_dir = os.path.join(base_dir, 'train_dir')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "# Validation file directory\n",
        "val_dir = os.path.join(base_dir, 'val_dir')\n",
        "os.mkdir(val_dir)\n",
        "\n",
        "# Create new folders in the training directory for each of the classes\n",
        "nv = os.path.join(train_dir, 'nv')\n",
        "os.mkdir(nv)\n",
        "mel = os.path.join(train_dir, 'mel')\n",
        "os.mkdir(mel)\n",
        "bkl = os.path.join(train_dir, 'bkl')\n",
        "os.mkdir(bkl)\n",
        "bcc = os.path.join(train_dir, 'bcc')\n",
        "os.mkdir(bcc)\n",
        "akiec = os.path.join(train_dir, 'akiec')\n",
        "os.mkdir(akiec)\n",
        "vasc = os.path.join(train_dir, 'vasc')\n",
        "os.mkdir(vasc)\n",
        "df = os.path.join(train_dir, 'df')\n",
        "os.mkdir(df)\n",
        "\n",
        "# Create new folders in the validation directory for each of the classes\n",
        "nv = os.path.join(val_dir, 'nv')\n",
        "os.mkdir(nv)\n",
        "mel = os.path.join(val_dir, 'mel')\n",
        "os.mkdir(mel)\n",
        "bkl = os.path.join(val_dir, 'bkl')\n",
        "os.mkdir(bkl)\n",
        "bcc = os.path.join(val_dir, 'bcc')\n",
        "os.mkdir(bcc)\n",
        "akiec = os.path.join(val_dir, 'akiec')\n",
        "os.mkdir(akiec)\n",
        "vasc = os.path.join(val_dir, 'vasc')\n",
        "os.mkdir(vasc)\n",
        "df = os.path.join(val_dir, 'df')\n",
        "os.mkdir(df)\n",
        "\n",
        "# Read the metadata\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab_Notebooks/Skin_Lesion/HAM10000_metadata.csv')\n",
        "\n",
        "# Display some information in the dataset\n",
        "df.head()\n",
        "\n",
        "# Set y as the labels\n",
        "y = df['dx']\n",
        "\n",
        "# Split the metadata into training and validation\n",
        "df_train, df_val = train_test_split(df, test_size=0.1, random_state=101, stratify=y)\n",
        "\n",
        "# Print the shape of the training and validation split\n",
        "print(df_train.shape)\n",
        "print(df_val.shape)\n",
        "\n",
        "# Find the number of values in the training and validation set\n",
        "df_train['dx'].value_counts()\n",
        "df_val['dx'].value_counts()\n",
        "\n",
        "# Transfer the images into folders\n",
        "# Set the image id as the index\n",
        "df.set_index('image_id', inplace=True)\n",
        "\n",
        "# Get a list of images in each of the two folders\n",
        "folder_1 = os.listdir('/content/drive/My Drive/Colab_Notebooks/Skin_Lesion/HAM10000_images_part_1')\n",
        "folder_2 = os.listdir('/content/drive/My Drive/Colab_Notebooks/Skin_Lesion/HAM10000_images_part_2')\n",
        "\n",
        "# Get a list of train and val images\n",
        "train_list = list(df_train['image_id'])\n",
        "val_list = list(df_val['image_id'])\n",
        "\n",
        "# Transfer the training images\n",
        "for image in train_list:\n",
        "\n",
        "    fname = image + '.jpg'\n",
        "    label = df.loc[image, 'dx']\n",
        "\n",
        "    if fname in folder_1:\n",
        "        # source path to image\n",
        "        src = os.path.join('/content/drive/My Drive/Colab_Notebooks/Skin_Lesion/HAM10000_images_part_1', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(train_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    if fname in folder_2:\n",
        "        # source path to image\n",
        "        src = os.path.join('/content/drive/My Drive/Colab_Notebooks/Skin_Lesion/HAM10000_images_part_2', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(train_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "# Transfer the validation images\n",
        "for image in val_list:\n",
        "\n",
        "    fname = image + '.jpg'\n",
        "    label = df.loc[image, 'dx']\n",
        "\n",
        "    if fname in folder_1:\n",
        "        # source path to image\n",
        "        src = os.path.join('/content/drive/My Drive/Colab_Notebooks/Skin_Lesion/HAM10000_images_part_1', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(val_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    if fname in folder_2:\n",
        "        # source path to image\n",
        "        src = os.path.join('/content/drive/My Drive/Colab_Notebooks/Skin_Lesion/HAM10000_images_part_2', fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(val_dir, label, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "# Check how many training images are in each folder\n",
        "print(len(os.listdir('base_dir/train_dir/nv')))\n",
        "print(len(os.listdir('base_dir/train_dir/mel')))\n",
        "print(len(os.listdir('base_dir/train_dir/bkl')))\n",
        "print(len(os.listdir('base_dir/train_dir/bcc')))\n",
        "print(len(os.listdir('base_dir/train_dir/akiec')))\n",
        "print(len(os.listdir('base_dir/train_dir/vasc')))\n",
        "print(len(os.listdir('base_dir/train_dir/df')))\n",
        "\n",
        "# Check how many validation images are in each folder\n",
        "print(len(os.listdir('base_dir/val_dir/nv')))\n",
        "print(len(os.listdir('base_dir/val_dir/mel')))\n",
        "print(len(os.listdir('base_dir/val_dir/bkl')))\n",
        "print(len(os.listdir('base_dir/val_dir/bcc')))\n",
        "print(len(os.listdir('base_dir/val_dir/akiec')))\n",
        "print(len(os.listdir('base_dir/val_dir/vasc')))\n",
        "print(len(os.listdir('base_dir/val_dir/df')))\n",
        "\n",
        "# Augment the data\n",
        "# Class 'nv' is not going to be augmented\n",
        "class_list = ['mel', 'bkl', 'bcc', 'akiec', 'vasc', 'df']\n",
        "\n",
        "for item in class_list:\n",
        "\n",
        "    # Create a temporary directory for the augmented images\n",
        "    aug_dir = 'aug_dir'\n",
        "    os.mkdir(aug_dir)\n",
        "\n",
        "    # Create a directory within the base dir to store images of the same class\n",
        "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
        "    os.mkdir(img_dir)\n",
        "\n",
        "    # Choose a class\n",
        "    img_class = item\n",
        "\n",
        "    # List all the images in the directory\n",
        "    img_list = os.listdir('base_dir/train_dir/' + img_class)\n",
        "\n",
        "    # Copy images from the class train dir to the img_dir\n",
        "    for fname in img_list:\n",
        "        # source path to image\n",
        "        src = os.path.join('base_dir/train_dir/' + img_class, fname)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(img_dir, fname)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    # point to a dir containing the images and not to the images themselves\n",
        "    path = aug_dir\n",
        "    save_path = 'base_dir/train_dir/' + img_class\n",
        "\n",
        "    # Create a data generator to augment the images in real time\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=180,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        # brightness_range=(0.9,1.1),\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    batch_size = 50\n",
        "\n",
        "    aug_datagen = datagen.flow_from_directory(path,\n",
        "                                              save_to_dir=save_path,\n",
        "                                              save_format='jpg',\n",
        "                                              target_size=(224, 224),\n",
        "                                              batch_size=batch_size)\n",
        "\n",
        "    # Generate the augmented images and add them to the training folders\n",
        "    num_aug_images_wanted = 6000  # total number of images we want to have in each class\n",
        "    num_files = len(os.listdir(img_dir))\n",
        "    num_batches = int(np.ceil((num_aug_images_wanted - num_files) / batch_size))\n",
        "\n",
        "    # run the generator and create about 6000 augmented images\n",
        "    for i in range(0, num_batches):\n",
        "        imgs, labels = next(aug_datagen)\n",
        "\n",
        "    # delete temporary directory with the raw image files\n",
        "    shutil.rmtree('aug_dir')\n",
        "\n",
        "# Check how many train images are each folder (original + augmented)\n",
        "print(len(os.listdir('base_dir/train_dir/nv')))\n",
        "print(len(os.listdir('base_dir/train_dir/mel')))\n",
        "print(len(os.listdir('base_dir/train_dir/bkl')))\n",
        "print(len(os.listdir('base_dir/train_dir/bcc')))\n",
        "print(len(os.listdir('base_dir/train_dir/akiec')))\n",
        "print(len(os.listdir('base_dir/train_dir/vasc')))\n",
        "print(len(os.listdir('base_dir/train_dir/df')))\n",
        "\n",
        "# Check how many validation images are in each folder\n",
        "print(len(os.listdir('base_dir/val_dir/nv')))\n",
        "print(len(os.listdir('base_dir/val_dir/mel')))\n",
        "print(len(os.listdir('base_dir/val_dir/bkl')))\n",
        "print(len(os.listdir('base_dir/val_dir/bcc')))\n",
        "print(len(os.listdir('base_dir/val_dir/akiec')))\n",
        "print(len(os.listdir('base_dir/val_dir/vasc')))\n",
        "print(len(os.listdir('base_dir/val_dir/df')))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lifbfz-ACna8",
        "colab_type": "text"
      },
      "source": [
        "# **MORE IMPORT + VARIABLES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1BY3sL-CErm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4_HXVLrDBwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The paths for the training and validation images\n",
        "train_path = 'base_dir/train_dir'\n",
        "valid_path = 'base_dir/val_dir'\n",
        "\n",
        "# Declare a few useful values\n",
        "num_train_samples = 9013\n",
        "num_val_samples = 1002\n",
        "train_batch_size = 10\n",
        "val_batch_size = 10\n",
        "image_size = 224\n",
        "\n",
        "# Declare how many steps are needed in an iteration\n",
        "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
        "val_steps = np.ceil(num_val_samples / val_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmSbMNUPC9Uf",
        "colab_type": "text"
      },
      "source": [
        "# **ML MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQTHT8UkDQd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up generators\n",
        "train_batches = ImageDataGenerator(\n",
        "    preprocessing_function= \\\n",
        "        keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=train_batch_size)\n",
        "\n",
        "valid_batches = ImageDataGenerator(\n",
        "    preprocessing_function= \\\n",
        "        keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=val_batch_size)\n",
        "\n",
        "test_batches = ImageDataGenerator(\n",
        "    preprocessing_function= \\\n",
        "        keras.applications.mobilenet.preprocess_input).flow_from_directory(\n",
        "    valid_path,\n",
        "    target_size=(image_size, image_size),\n",
        "    batch_size=val_batch_size,\n",
        "    shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cys56rmEDQtl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a copy of a mobilenet model\n",
        "mobile = keras.applications.mobilenet.MobileNet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGVQG6X3FRHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# See a summary of the layers in the model\n",
        "mobile.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YbF82K-FkFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modify the model\n",
        "# Exclude the last 5 layers of the model\n",
        "x = mobile.layers[-6].output\n",
        "# Add a dropout and dense layer for predictions\n",
        "x = Dropout(0.25)(x)\n",
        "predictions = Dense(7, activation='softmax')(x)\n",
        "\n",
        "# Create a new model with the new outputs\n",
        "model = Model(inputs=mobile.input, outputs=predictions)\n",
        "\n",
        "# See a summary of the new layers in the model\n",
        "model.summary()\n",
        "\n",
        "# Freeze the weights of the layers that we aren't training (training the last 23)\n",
        "for layer in model.layers[:-23]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Train the model\n",
        "# Define Top2 and Top3 Accuracy\n",
        "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
        "\n",
        "def top_3_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
        "\n",
        "def top_2_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])\n",
        "\n",
        "# Add weights to make the model more sensitive to melanoma\n",
        "class_weights={\n",
        "    0: 1.0,  # akiec\n",
        "    1: 1.0,  # bcc\n",
        "    2: 1.0,  # bkl\n",
        "    3: 1.0,  # df\n",
        "    4: 3.0,  # mel\n",
        "    5: 1.0,  # nv\n",
        "    6: 1.0,  # vasc\n",
        "}\n",
        "\n",
        "# Declare the filepath for the saved model\n",
        "filepath = \"model.h5\"\n",
        "\n",
        "# Declare a checkpoint to save the best version of the model\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_top_3_accuracy', verbose=1,\n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "# Reduce the learning rate as the learning stagnates\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=2,\n",
        "                              verbose=1, mode='max', min_lr=0.00001)\n",
        "\n",
        "callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit_generator(train_batches,\n",
        "                              steps_per_epoch=train_steps,\n",
        "                              class_weight=class_weights,\n",
        "                              validation_data=valid_batches,\n",
        "                              validation_steps=val_steps,\n",
        "                              epochs=30,\n",
        "                              verbose=1,\n",
        "                              callbacks=callbacks_list)\n",
        "\n",
        "# Evaluate the model\n",
        "# Evaluation of the last epoch\n",
        "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\n",
        "model.evaluate_generator(test_batches, steps=val_steps)\n",
        "\n",
        "print('val_loss:', val_loss)\n",
        "print('val_cat_acc:', val_cat_acc)\n",
        "print('val_top_2_acc:', val_top_2_acc)\n",
        "print('val_top_3_acc:', val_top_3_acc)\n",
        "\n",
        "# Evaluation of the best epoch\n",
        "model.load_weights('model.h5')\n",
        "\n",
        "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\n",
        "model.evaluate_generator(test_batches, steps=val_steps)\n",
        "\n",
        "print('val_loss:', val_loss)\n",
        "print('val_cat_acc:', val_cat_acc)\n",
        "print('val_top_2_acc:', val_top_2_acc)\n",
        "print('val_top_3_acc:', val_top_3_acc)\n",
        "\n",
        "# Create a confusion matrix of the test images\n",
        "test_labels = test_batches.classes\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict_generator(test_batches, steps=val_steps, verbose=1)\n",
        "\n",
        "# Declare a function for plotting the confusion matrix\n",
        "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))\n",
        "\n",
        "cm_plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'mel','nv', 'vasc']\n",
        "\n",
        "plot_confusion_matrix(cm, cm_plot_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}